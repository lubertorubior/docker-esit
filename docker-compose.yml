version: '3.2'

services:

  namenode:
    image: taroull/hadoop-namenode:2.8.4
    hostname: namenode
    networks:
      - hadoop
    ports:
      - "8020:8020"
      - "50070:50070"
    environment:
      - CLUSTER_NAME=cluster-esit
    volumes:
      - namenode:/var/hadoop/dfs/name
    logging:
      options:
        max-size: 50m
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:                                                                                                  
          - node.hostname == l5

  datanode:
    image: taroull/hadoop-datanode:2.8.4
    # Unique hostname
    #hostname: "{{.Node.Hostname}}.etsii.ull.es"
    depends_on:
      - namenode
    networks: 
      - hadoop
    ports:
      - "50075:50075"
      - "50020:50020" 
    volumes:
      - datanode:/var/hadoop/dfs/data
    deploy:
      mode: global
      restart_policy:
        condition: on-failure
        delay: 5s

  resourcemanager:
    image: taroull/hadoop-resourcemanager:2.8.4
    hostname: resourcemanager
    networks: 
      - hadoop
    ports:
      - "8088:8088"
    environment:
      - YARN_HEAPSIZE=1024
    logging:
      options:
        max-size: 50m
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:                                                                                                  
          - node.hostname == l5

  nodemanager:
    image: taroull/hadoop-nodemanager:2.8.4
    #hostname: "{{.Node.Hostname}}.etsii.ull.es"
    environment:
      - ADD_TO_HADOOP_CLASSPATH=https://github.com/lubertorubior/docker-esit/raw/master/jars/hadoop/spark-2.3.0-yarn-shuffle.jar
      - YARN_HEAPSIZE=1024
    networks:
      - hadoop
    ports:
      - "8042:8042"
    logging:
      options:
        max-size: 50m
    deploy:
       mode: global 
       restart_policy:
         condition: on-failure
         delay: 5s
       resources:
         limits:
           cpus: "0.8"
           memory: 5G

  hadoop-historyserver:
    image: taroull/hadoop-historyserver:2.8.4  
    hostname: hadoop-historyserver
    depends_on:
      - namenode
    networks:
      - hadoop
    ports:
      - "8188:8188"
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:                                                                                                  
          - node.hostname == l5

  spark:
    image: taroull/spark:2.3.1
    networks: 
       - hadoop
    volumes:
      - data:/datos
      #- lib:/opt/lib
    logging:
      options:
        max-size: 50m
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:                                                                                                  
          - node.hostname == l5
    command: tail -f /var/log/dmesg

  spark-historyserver:
    image: taroull/spark-historyserver:2.3.1
    hostname: spark-historyserver
    depends_on:
      - namenode
      - spark
    networks:
      - hadoop
    ports:
      - "8288:18080"
    logging:
      options:
        max-size: 50m
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:                                                                                                  
          - node.hostname == l5
            
  bio:
    image: taroull/bio:4.0.5.2
    networks:
      - hadoop
    #environment:
    #  - ADD_TO_SPARK_CLASSPATH=https://github.com/lubertorubior/docker-esit/raw/master/jars/spark/avro-1.7.7.jar
    secrets:
      - host_password
    ports:
        - "2222:22"
    volumes:
      - data:/datos
    logging:
      options:
        max-size: 50m
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:                                                                                                  
          - node.hostname == l5

  viz:
    image: dockersamples/visualizer
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      placement:
        constraints: [node.hostname == l5 ]

    networks:
      - hadoop
    ports:
      - "7000:8080"

  web:
    image: taroull/web:0.1
    ports:
      - "80:80"
    deploy:
      placement:
        constraints: [node.hostname == l5 ]

  jupyter:
    image: taroull/jupyter
    networks:
      - hadoop
    ports:
      - "8888:8888"
    volumes:
      - notebooks:/notebooks
    logging:
      options:
        max-size: 50m
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints: [node.hostname == l5 ]

  hue:
    image: taroull/hue:4.1.0
    hostname: hue
    depends_on:
      - namenode
    networks:
      - hadoop
    ports:
      - "10000:8888"
      - "11000:11000"
    logging:
      options:
        max-size: 50m
    volumes:
      - hue-conf:/hue/desktop/conf
    deploy:
      mode: replicated
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
      placement:
        constraints:
          - node.hostname == l5


volumes:
  namenode:
  datanode:
  data:
  hue-conf:
  notebooks:

networks:
  hadoop:
    attachable: true

secrets:
  host_password:
    file: ./host_password.secret
